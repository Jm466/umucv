{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "<img src=\"../images/demos/FIUM.png\" width=\"350px\" class=\"pull-right\" style=\"display: inline-block\">\n",
    "\n",
    "# Visión Artificial\n",
    "\n",
    "### 4º de Grado en Ingeniería Informática\n",
    "\n",
    "Curso 2019-2020<br>\n",
    "Prof. [*Alberto Ruiz*](http://dis.um.es/profesores/alberto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![concept map](../images/demos/concept_map.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [libro de Szeliski](http://szeliski.org/Book/drafts/SzeliskiBook_20100903_draft.pdf)\n",
    "\n",
    "\n",
    "- [OpenCV](https://opencv.org/), [tutoriales en Python](https://docs.opencv.org/4.1.0/d6/d00/tutorial_py_root.html), [documentación](https://docs.opencv.org/4.1.0/)\n",
    "\n",
    "- [libro](https://books.google.es/books?id=seAgiOfu2EIC&printsec=frontcover)\n",
    "\n",
    "- [libro1](https://books.google.es/books?id=9uVOCwAAQBAJ&printsec=frontcover), [libro2](https://books.google.es/books?id=iNlOCwAAQBAJ&printsec=frontcover)\n",
    "\n",
    "\n",
    "- [scikit-image](http://scikit-image.org/), [scikit-learn](http://scikit-learn.org)\n",
    "\n",
    "\n",
    "- [datasets](https://en.wikipedia.org/wiki/List_of_datasets_for_machine_learning_research#Image_data)\n",
    "\n",
    "\n",
    "- [Python](https://docs.python.org/3.6/)\n",
    "\n",
    "- [numpy](http://www.numpy.org/), [scipy](http://docs.scipy.org/doc/scipy/reference/)\n",
    "\n",
    "- [matplotlib](http://matplotlib.org/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prácticas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Preguntas frecuentes](FAQ.ipynb)\n",
    "\n",
    "\n",
    "- [Guión de las sesiones](guionpracticas.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Presentación (3/2/20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[introducción](intro.ipynb), [instalación](install.ipynb), [Python](python.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Introducción a la asignatura\n",
    "\n",
    "- Repaso de Python, numpy y matplotib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introducción a la imagen digital (10/2/20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[imagen](imagen.ipynb), [gráficas](graphs.ipynb), [indexado/stacks](stacks.ipynb), [dispositivos de captura](captura.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Imagen digital: rows, cols, depth, step. Planar or pixel order. Tipo de pixel: byte vs float\n",
    "\n",
    "- Color encoding: RGB vs YUV vs HSV\n",
    "\n",
    "- Campo de visión (FOV, *field of view*, parámetro $f$)\n",
    "\n",
    "- Coordendas de pixel, coordenadas normalizadas (indep de resolución), coordenadas calibradas (independiente del FOV).\n",
    "\n",
    "- Aspect ratio. Resize.\n",
    "\n",
    "- Manipulación: slice regions, \"stack\" de imágenes\n",
    "\n",
    "- primitivas gráficas\n",
    "\n",
    "- captura: webcams, cameras ip, archivos de vídeo, v4l2-ctl, etc. Load / save.\n",
    "\n",
    "- entornos de conda, pyqtgraph, pycharm, spyder\n",
    "\n",
    "- Herramientas: formatos de imagen, imagemagick, gimp, mplayer/mencoder/ffmpeg, mpv, gstreamer, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Manipulación de imágenes (17/2/20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[canales de color](color.ipynb), [histograma](histogram.ipynb), [efecto chroma](chroma.ipynb), [segmentación por color](colorseg.ipynb)\n",
    "<br>\n",
    "[cuantización de color](codebook.ipynb), [transformaciones de dominio](lookup.ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ROIs, masks\n",
    "\n",
    "- Componentes conexas vs contornos.\n",
    "\n",
    "- inRange\n",
    "\n",
    "- Chroma key\n",
    "\n",
    "- Histograma, transformaciones de valor (brillo, contraste), ecualización\n",
    "\n",
    "- Histograma nD\n",
    "\n",
    "- Distancia entre histogramas. Reproyección de histograma\n",
    "\n",
    "- Transformaciones de dominio (deformaciones), lookup table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Filtros digitales (24/02/20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[filtros de imagen](filtros.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- lineal\n",
    "\n",
    "    - convolution\n",
    "    - máscaras para paso alto, bajo, etc.\n",
    "    - separabilidad\n",
    "    - integral image, box filter\n",
    "    - dominio frecuencial\n",
    "    - [inverse filtering](http://yuzhikov.com/articles/BlurredImagesRestoration1.htm), [Wiener](https://www.cis.rit.edu/class/simg782/lectures/lecture_16/lec782_05_16.pdf)\n",
    "\n",
    "\n",
    "- no lineal\n",
    "\n",
    "    - mediana\n",
    "    - min, max\n",
    "    - algoritmos generales\n",
    "\n",
    "\n",
    "- Gaussian filter\n",
    "\n",
    "    - separabilidad\n",
    "    - cascading\n",
    "    - Fourier\n",
    "    - scale space\n",
    "\n",
    "\n",
    "\n",
    "- [morphological operations](http://docs.opencv.org/master/d9/d61/tutorial_py_morphological_ops.html#gsc.tab=0)\n",
    "\n",
    "    - structuring element\n",
    "    - dilate, erode\n",
    "    - open, close\n",
    "    - gradient\n",
    "    - fill holes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4. Detección de bordes (02/03/20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[detección de bordes](bordes.ipynb), [Canny nms en C](cannyC.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- gradiente: visualización como *vector field*\n",
    "\n",
    "- operador de Canny\n",
    "\n",
    "- transformada de Hough\n",
    "\n",
    "- Histograma de orientaciones del gradiente (HOG)\n",
    "\n",
    "- implementación simple de HOG\n",
    "\n",
    "- detección de *pedestrians*\n",
    "\n",
    "- face landmarks (dlib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Flujo óptico (09/03/20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[elipse de incertidumbre](covarianza.ipynb), [optical flow](harris.ipynb)\n",
    "\n",
    "- elipse de incertidumbre\n",
    "\n",
    "- cross-correlation\n",
    "\n",
    "- corners (Harris)\n",
    "\n",
    "- Lucas-Kanade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. *Keypoints* (16/03/20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[keypoints](keypoints.ipynb), [bag of visual words](bag-of-words.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- modelo cuadrático\n",
    "\n",
    "- blobs / saddle points (Hessian)\n",
    "\n",
    "- SIFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7a. Análisis frecuencial (23/03/20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[análisis frecuencial](fourier.ipynb), [filtrado inverso](inversefilt.ipynb)\n",
    "\n",
    "(Conclusión del capítulo 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7b. Reconocimiento de formas (23/03/20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[shapes](shapes.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- umbralización\n",
    "\n",
    "- análisis de regiones (componentes conexas, transformada de distancia)\n",
    "\n",
    "- manipulación de contornos\n",
    "\n",
    "- invariantes frecuenciales de forma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Deep learning*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[machine learning](machine-learning.ipynb), [tensorflow](tensorflow.ipynb)\n",
    "\n",
    "- Repaso de *Machine Learning* y *Pattern Recognition*\n",
    "\n",
    "- Repaso de computación neuronal\n",
    "\n",
    "- Introducción a la redes convolucionales\n",
    "\n",
    "- *Deep Learning* en visión artificial.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otras técnicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[varios](varios.ipynb), [textura](textura.ipynb), [`grabcut.py`](../code/grabcut.py), [transformada de distancia](transf-dist.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Detección de caras mediante *adaboost* ([Viola & Jones, 2001](https://en.wikipedia.org/wiki/Viola%E2%80%93Jones_object_detection_framework))\n",
    "\n",
    "- Segmentación de objetos mediante *GrabCut* ([Rother et al. 2004](https://cvg.ethz.ch/teaching/cvl/2012/grabcut-siggraph04.pdf), [tutorial](http://docs.opencv.org/3.2.0/d8/d83/tutorial_py_grabcut.html))\n",
    "\n",
    "- Clasificación de texturas mediante *LBP* ([Wang and He, 1990](http://www.academia.edu/download/46467306/0031-3203_2890_2990135-820160614-8960-12m30mo.pdf), [wiki](https://en.wikipedia.org/wiki/Local_binary_patterns))\n",
    "\n",
    "- Herramientas para OCR (*[tesseract](https://github.com/tesseract-ocr)*)\n",
    "\n",
    "- Herramientas para códigos de barras y QR (*[zbar](http://zbar.sourceforge.net/)*)\n",
    "\n",
    "- Detección de elipses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coordenadas homogéneas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos el estudio de la geometría visual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[perspectiva](geovis.ipynb), [coordenadas homogéneas](coordhomog.ipynb), [sistemas de ecuaciones](sistecs.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformaciones lineales\n",
    "\n",
    "- espacios lineales, vectores\n",
    "\n",
    "- transformaciones lineales, matrices\n",
    "\n",
    "- producto escalar (**dot** product)\n",
    "\n",
    "- producto vectorial (**cross** product)\n",
    "\n",
    "- puntos, rectas, planos, meet & join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geometría del plano\n",
    "\n",
    "- coordenadas homogéneas\n",
    "\n",
    "- interpretación como rayos\n",
    "\n",
    "- puntos y rectas del plano\n",
    "\n",
    "- incidencia e intersección, dualidad\n",
    "\n",
    "- puntos del infinito, recta del infinito\n",
    "\n",
    "- manejo natural de puntos del infinito\n",
    "\n",
    "- horizonte de un plano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformaciones del plano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[transformaciones del plano](transf2D.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Desplazamientos, rotaciones, escalado uniforme, escalado general, proyectividad.\n",
    "\n",
    "- Grupos euclídeo, similar, afín, proyectivo.\n",
    "\n",
    "- Propiedades invariantes de cada grupo.\n",
    "\n",
    "- Representación como matriz homogénea $3\\times 3$ y tipos de matriz de cada grupo.\n",
    "\n",
    "- *Cross ratio* de 4 puntos en una recta. De 5 rectas.\n",
    "\n",
    "- Estimación de transformaciones a partir de correspondencias.\n",
    "\n",
    "- Aplicaciones: rectificación de planos, mosaico de imágenes.\n",
    "\n",
    "Avanzado\n",
    "\n",
    "- Transformación de rectas. Covarianza y contravarianza.\n",
    "\n",
    "- Cónicas: incidencia, tangencia, (pole-polar), cónica dual, transformación.\n",
    "\n",
    "- Objetos invariantes en cada grupo de transformaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de cámara"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[modelo de la cámara](camera.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Espacio proyectivo: puntos y líneas 3D, planos, grados de libertad, plano del infinito, analogía con 2D.\n",
    "\n",
    "- Grupos de transformaciones 3D: y sus invariantes.\n",
    "\n",
    "- Modelo pinhole (proyección), cámara oscura, lente.\n",
    "\n",
    "- Transformación de perspectiva: proyección $\\mathcal P^3 \\rightarrow\\mathcal P ^2$.\n",
    "\n",
    "- cámara calibrada C=PRT, 6 dof, parámetros extrínsecos o pose.\n",
    "\n",
    "- calibración, distorsión radial.\n",
    "\n",
    "- Matriz de cámara estándar $M=K[R|t]$.\n",
    "\n",
    "- Matriz de calibración $K$ y campo visual. Calibración \"a ojo\" de una cámara mediante estimación de su FOV.\n",
    "\n",
    "- PnP (*pose from n points*).\n",
    "\n",
    "- Realidad aumentada.\n",
    "\n",
    "- Anatomía de la cámara\n",
    "\n",
    "- Rotaciones sintéticas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimentos\n",
    "\n",
    "- Rectificación de planos mediante rotaciones sintéticas.\n",
    "\n",
    "- Experimenta con [ARToolkit](http://artoolkit.org).\n",
    "\n",
    "- Echa un vistazo a [PTAM](http://www.robots.ox.ac.uk/~gk/PTAM)\n",
    "\n",
    "- Navegación visual de robots.\n",
    "\n",
    "- Haz un programa que capture con la webcam la imagen de un sudoku y lo resuelva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visión estéreo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[stereo](stereo.ipynb), [stereo-challenge](stereo-challenge.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Triangulación\n",
    "\n",
    "- Geometría epipolar\n",
    "\n",
    "- Extracción de cámaras\n",
    "\n",
    "- Rectificación estéreo\n",
    "\n",
    "- Mapas de profundidad\n",
    "\n",
    "\n",
    "Experimentos\n",
    "\n",
    "- Reproduce los experimentos con un par estéreo tomado con tu propia cámara usando el *tracker* de puntos estudiado en una clase anterior.\n",
    "\n",
    "- Intenta poner en marcha el sistema [VisualSFM](http://ccwu.me/vsfm/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [introducción](intro.ipynb)\n",
    "1. [instalación](install.ipynb)\n",
    "1. [Python](python.ipynb)\n",
    "\n",
    "1. [dispositivos de captura](captura.ipynb)\n",
    "\n",
    "1. [imagen](imagen.ipynb)\n",
    "1. [gráficas](graphs.ipynb)\n",
    "1. [canales de color](color.ipynb)\n",
    "\n",
    "1. [indexado, stacks](stacks.ipynb)\n",
    "1. [histograma](histogram.ipynb)\n",
    "1. [efecto chroma](chroma.ipynb)\n",
    "1. [segmentación por color](colorseg.ipynb)\n",
    "1. [cuantización de color](codebook.ipynb)\n",
    "\n",
    "1. [transformaciones de dominio](lookup.ipynb) \n",
    "\n",
    "1. [filtros de imagen](filtros.ipynb)\n",
    "1. [análisis frecuencial](fourier.ipynb)\n",
    "1. [filtrado inverso](inversefilt.ipynb)\n",
    "\n",
    "1. [transformada de distancia](transf-dist.ipynb)\n",
    "\n",
    "1. [detección de bordes](bordes.ipynb)\n",
    "\n",
    "1. [técnicas auxiliares](ipmisc.ipynb)\n",
    "1. [Canny nms en C](cannyC.ipynb)\n",
    "\n",
    "1. [elipse de incertidumbre](covarianza.ipynb)\n",
    "1. [optical flow](harris.ipynb)\n",
    "\n",
    "1. [keypoints](keypoints.ipynb)\n",
    "1. [bag of visual words](bag-of-words.ipynb)\n",
    "\n",
    "1. [sistemas de ecuaciones](sistecs.ipynb)\n",
    "\n",
    "1. [textura](textura.ipynb)\n",
    "\n",
    "1. [shapes](shapes.ipynb)\n",
    "\n",
    "1. [varios](varios.ipynb)\n",
    "\n",
    "1. [perspectiva](geovis.ipynb)\n",
    "1. [coordenadas homogéneas](coordhomog.ipynb)\n",
    "1. [transformaciones del plano](transf2D.ipynb)\n",
    "1. [DLT](DLT.ipynb)\n",
    "\n",
    "1. [modelo de cámara](camera.ipynb)\n",
    "\n",
    "1. [visión stereo](stereo.ipynb)\n",
    "1. [stereo-challenge](stereo-challenge.ipynb)\n",
    "\n",
    "1. [machine learning](machine-learning.ipynb)\n",
    "1. [tensorflow](tensorflow.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos de código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [`hello.py`](../code/hello.py): lee imagen de archivo, la reescala, muestra y sobreescribe un texto.\n",
    "\n",
    "1. [`webcam.py`](../code/webcam.py): muestra la secuencia de imágenes capturadas por una webcam.\n",
    "\n",
    "1. [`2cams.py`](../code/2cams.py): combina las imágenes tomadas por dos cámaras.\n",
    "\n",
    "1. [`player.py`](../code/player.py): función auxiliar que permite aplicar una cierta función a la secuencia de imágenes, con opción de guardar (S) y parar el vídeo (espacio).\n",
    "\n",
    "1. [`mouse.py`](../code/mouse.py): ejemplo de captura de eventos de ratón.\n",
    "\n",
    "1. [`trackbar.py`](../code/trackbar.py): ejemplo de parámetro interactivo.\n",
    "\n",
    "1. [`stream.py`](../code/stream.py): ejemplo de uso de la fuente genérica de imágenes \"mkStream\".\n",
    "\n",
    "1. [`video_save.py`](../code/video_save.py): ejemplo de uso de la utilidad de grabación de vídeo.\n",
    "\n",
    "1. [`deque.py`](../code/deque.py): procesamiento de las $n$ imágenes más recientes.\n",
    "\n",
    "1. [`mjpegserver.py`](../code/mjpegserver.py): servidor de secuencias de video en formato mjpeg.\n",
    "\n",
    "1. [`histogram.py`](../code/histogram.py): histograma en vivo con opencv.\n",
    "\n",
    "1. [`histogram2.py`](../code/histogram2.py): histograma en vivo con matplotlib.\n",
    "\n",
    "1. [`surface.py`](../code/surface.py): superficie 3D de niveles de gris en vivo usando pyqtgraph.\n",
    "\n",
    "1. [`inrange.py`](../code/inrange.py): umbralización de color, máscaras, componentes conexas y contornos.\n",
    "\n",
    "1. [`backsub.py`](../code/backsub.py): eliminación de fondo mediante MOG2.\n",
    "\n",
    "1. [`server.py`](../code/server.py): ejemplo de servidor web de imágenes capturadas con la webcam.\n",
    "\n",
    "1. [`bot`](../code/bot): bots de [Telegram](https://python-telegram-bot.org/).\n",
    "\n",
    "1. [`reprohist.py`](../code/reprohist.py),  [`mean-shift.py`](../code/mean-shift.py), [`camshift.py`](../code/camshift.py): reproyección de histograma y tracking.\n",
    "\n",
    "1. [`grabcut.py`](../code/grabcut.py): segmentación de objetos interactiva mediante GrabCut.\n",
    "\n",
    "1. [`spectral.py`](../code/spectral.py): FFT en vivo.\n",
    "\n",
    "1. [`thread`](../code/thread): captura y procesamiento concurrente.\n",
    "\n",
    "1. [`testC.py`](../code/testC.py), [`inC`](../code/inC): Interfaz C-numpy.\n",
    "\n",
    "1. [`hog/pedestrian.py`](../code/hog/pedestrian.py): detector de peatones de opencv.\n",
    "\n",
    "1. [`hog/facelandmarks.py`](../code/hog/facelandmarks.py): detector de caras y landmarks de dlib.\n",
    "\n",
    "1. [`hog/hog0.py`](../code/hog/hog0.py): experimentos con hog.\n",
    "\n",
    "1. [`regressor.py`](../code/regressor.py): predictor directo de la posición de una región.\n",
    "\n",
    "1. [`LK/*.py`](../code/LK): seguimiento de puntos con el método de Lucas-Kanade.\n",
    "\n",
    "1. [`SIFT/*.py`](../code/sift.py): demostración de la detección de keypoints y búsqueda de coincidencias en imágenes en vivo.\n",
    "\n",
    "1. [`inception.py`](../code/inception.py): clasificación de objetos con la red convolucional InceptionV3 entrenada con la base de datos imagenet, disponible en keras.\n",
    "\n",
    "1. [`openpose.py`](../code/openpose.py): estimación de postura de cuerpo humano mediante [openpose](https://github.com/ildoonet/tf-pose-estimation).\n",
    "\n",
    "1. [`stitcher.py`](../code/stitcher.py): construcción automática de panoramas.\n",
    "\n",
    "1. [`pose.py`](../code/pose.py), [`pose3D.py`](../code/pose3D.py): estimación de cámara y realidad aumentada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los ejercicios se deben presentar en un notebook *jupyter* o en documento *pdf* que incluya el **código** realizado, una **explicación** detallada y **resultados** de funcionamieno con imágenes de evaluación **originales**. Se recomienda incluir información sobre tiempos de cómputo y limitaciones de las soluciones propuestas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obligatorios** (provisional): FOV, {DMOV | CHRO}, {HISTCOL | SEGCOL}, {DLIB | VROT}, SIFT, RECTIF, PANO, RA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Z**. Pon en marcha el entorno de trabajo, incluyendo entre otros, los módulos y herramientas jupyter, spyder/pycharm, opencv, numpy, matplolib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FOV**. Estima de forma aproximada el campo de visión ([FOV](https://en.wikipedia.org/wiki/Angle_of_view)) y parámetro $f$ de tu cámara. Determina a qué altura habría que ponerla para obtener una vista cenital completa de un campo de baloncesto. Calcula la altura de una pelota sobre el suelo a partir de su tamaño en la imagen.\n",
    "\n",
    "Realiza una calibración precisa de tu cámara mediante múltiples imágenes de un *chessboard* y compara el parámetro $f$ obtenido con el resultado anterior.\n",
    "\n",
    "Si la cámara incluye metadatos en las imágenes y aparece la *Focal Length*, puedes comprobar si este valor es coherente con el que tú obtienes.\n",
    "\n",
    "[Más informacion](FAQ.ipynb#Ejercicio-FOV)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MSAT**. Modifica los canales de color (tono, saturación, etc.) de una secuencia de imágenes en vivo con un \"trackbar\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DMOV**. Construye un detector de movimiento basado en una sencilla diferencia de imágenes sucesivas. Opcionalmente puedes hacer un generador que filtre la secuencia de imágenes dejando pasar solo los frames estáticos (o, alternativamente, los que han sufrido un cambio apreciable. En este caso no hace falta detectar las zonas con movimiento). Puedes apoyarte en `deque.py`. Opcional: a) Limitar la detección a una región de interés. b) Guardar 2 ó 3 segundos de la secuencia detectada en un archivo de vídeo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CHRO**. Implementa el efecto chroma con imágenes en vivo de la webcam. Pulsando una tecla se captura el fondo y los objetos que aparezcan se superponen en otra imagen o secuencia de video. Se trata de conseguir un resultado [como el que se muestra aquí](../images/demos/chroma.png), pero en vivo. Opcional: compara el resultado con el método automático de eliminación de fondo ilustrado en `backsub.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SROI**. Escribe una herramienta para seleccionar con el ratón varias regiones de interés (ROI), almacenando los recortes en una lista, y opcionalmente en disco. (Puedes usar la clase ROI que vimos en `mean-shift`.) Será útil en futuros ejercicios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HISTCOL**. Construye un clasificador de objetos en base a la similitud de los histogramas de color del ROI (de los 3 canales por separado). Apóyate en SROI. [Más información](FAQ.ipynb#Ejercicio-HISTCOL)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SEGCOL**. Implementa la segmentación por color usando reproyección de histogramas en un programa que admite como argumento a) una carpeta con trozos de imágen que sirven como muestras de color y b) otra imagen o secuencia de video que deseamos clasificar. El resultado puede ser un conjunto de máscaras para cada clase, o una \"imagen de etiquetas\", donde diferentes colores indican cada una de las regiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ROBCOL**. Evalúa la robustez del programa `inrange.py` realizado en prácticas en una escena real tomada desde distintas posiciones y condiciones de iluminación. Amplíalo para tener en cuenta que el color rojo aparece en dos zonas del canal H y para seleccionar un intervalo de áreas permitidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FIL**. Muestra el efecto de diferentes filtros sobre la imagen en vivo de la webcam. Selecciona con el teclado el filtro deseado y modifica sus posibles parámetros (p.ej. el nivel de suavizado) con las teclas de flecha. Es conveniente permitir la selección de un ROI para comparar el resultado del filtro con el resto de la imagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DLIB**. Escribe una aplicación de tu invención que utilice los [marcadores de cara](https://ibug.doc.ic.ac.uk/resources/facial-point-annotations/) obtenidos por el *shape detector* disponible en [dlib](http://dlib.net/) (ejemplo `/hog/facelandmarks.py`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VROT**. Estima de forma aproximada la velocidad angular de rotación de la cámara (grados/segundo) analizando las trayectorias obtenidas por el *tracker* de Lucas-Kanade (ejemplo `LK/lk_track.py`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WEB**. Construye un servidor web sencillo usando [flask](http://flask.pocoo.org/) que muestre una cierta transformación, especificada en la url, de las imágenes tomadas con la cámara. Apóyate en `server.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SIFT**. Escribe una aplicación de reconocimiento de objetos (p. ej. carátulas de CD, portadas de libros, cuadros de pintores, etc.) con la webcam basada en el número de coincidencias de *keypoints*. [Más información](FAQ.ipynb#Ejercicio-SIFT)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SILU**. Escribe una aplicación de reconocimiento de siluetas con la webcam basado en descriptores frecuenciales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OCR**. Escribe una aplicación de reconocimiento de dígitos manuscritos con la webcam. Compara el clasificador gaussiano y la red convolucional explicada en el capítulo de machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RECTIF**. Rectifica la imagen de un plano para medir distancias (tomando manualmente referencias conocidas). Por ejemplo, mide la distancia entre las monedas en `coins.png` o la distancia a la que se realiza el disparo en `gol-eder.png`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PANO**. Crea automáticamente un mosaico panorámico ajustando varias imágenes (>2). Recuerda que debe tratarse de una escena plana o de una escena cualquiera vista desde el mismo centro de proyección."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RA**. Crea un efecto de realidad aumentada dinámico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SUDO**. Haz un programa capaz de rellenar un sudoku que se observa en la imagen en vivo de la webcam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STC**. Resuelve los problemas planteados en el notebook [stereo-challenge](stereo-challenge.ipynb)."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "nbTranslate": {
   "displayLangs": [
    "en",
    "es"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "es",
   "targetLang": "en",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
