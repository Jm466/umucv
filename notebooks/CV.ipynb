{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "# Visión Artificial\n",
    "\n",
    "### 4º Grado en Ingeniería Informática\n",
    "\n",
    "Curso 2017-2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## recursos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [libro de Szeliski](http://szeliski.org/Book/drafts/SzeliskiBook_20100903_draft.pdf)\n",
    "\n",
    "- [OpenCV](https://opencv.org/), [tutoriales en Python](https://docs.opencv.org/3.3.1/d6/d00/tutorial_py_root.html)\n",
    "\n",
    "- [scikit-image](http://scikit-image.org/), [scikit-learn](http://scikit-learn.org)\n",
    "\n",
    "\n",
    "- [TensorFlow](https://www.tensorflow.org/)\n",
    "\n",
    "- [ImageNet](http://www.image-net.org)\n",
    "\n",
    "- [datasets](https://en.wikipedia.org/wiki/List_of_datasets_for_machine_learning_research#Image_data)\n",
    "\n",
    "\n",
    "- [Python](https://docs.python.org/3.6/)\n",
    "\n",
    "- [numpy](http://www.numpy.org/), [scipy](http://docs.scipy.org/doc/scipy/reference/)\n",
    "\n",
    "- [matplotlib](http://matplotlib.org/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [instalación](install.ipynb)\n",
    "\n",
    "1. [dispositivos de captura](captura.ipynb)\n",
    "\n",
    "1. [gráficas](graphs.ipynb)\n",
    "1. [canales de color](color.ipynb)\n",
    "\n",
    "1. [indexado, stacks](stacks.ipynb)\n",
    "1. [histograma](histogram.ipynb)\n",
    "1. [efecto chroma](chroma.ipynb)\n",
    "1. [segmentación por color](colorseg.ipynb)\n",
    "1. [cuantización de color](codebook.ipynb)\n",
    "\n",
    "1. [transformaciones de dominio](lookup.ipynb) \n",
    "\n",
    "1. [filtros de imagen](filtros.ipynb)\n",
    "1. [análisis frecuencial](fourier.ipynb)\n",
    "1. [filtrado inverso](inversefilt.ipynb)\n",
    "\n",
    "1. [detección de bordes](bordes.ipynb)\n",
    "\n",
    "1. [técnicas auxiliares](ipmisc.ipynb)\n",
    "1. [Canny nms en C](cannyC.ipynb)\n",
    "\n",
    "1. [keypoints](keypoints.ipynb)\n",
    "\n",
    "1. [elipse de incertidumbre](covarianza.ipynb)\n",
    "1. [optical flow](harris.ipynb)\n",
    "\n",
    "1. [sistemas de ecuaciones](sistecs.ipynb)\n",
    "\n",
    "1. [textura](textura.ipynb)\n",
    "\n",
    "1. [shapes](shapes.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## programas de ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [`hello.py`](../code/hello.py): lee imagen de archivo, la reescala, muestra y sobreescribe un texto.\n",
    "\n",
    "1. [`webcam.py`](../code/webcam.py): muestra la secuencia de imágenes capturadas por una webcam.\n",
    "\n",
    "1. [`2cams.py`](../code/2cams.py): combina las imágenes tomadas por dos cámaras.\n",
    "\n",
    "1. [`player.py`](../code/player.py): función auxiliar que permite aplicar una cierta función a la secuencia de imágenes, con opción de guardar (S) y parar el vídeo (espacio).\n",
    "\n",
    "1. [`mouse.py`](../code/mouse.py): ejemplo de captura de eventos de ratón.\n",
    "\n",
    "1. [`trackbar.py`](../code/trackbar.py): ejemplo de parámetro interactivo.\n",
    "\n",
    "1. [`stream.py`](../code/stream.py): ejemplo de uso de la fuente genérica de imágenes \"mkStream\".\n",
    "\n",
    "1. [`stream2.py`](../code/stream2.py): ejemplo de mkStream para leer un conjunto de imágenes en disco mostrándolas y avanzando de una en una pulsando una tecla.\n",
    "\n",
    "1. [`deque.py`](../code/deque.py): procesamiento de las $n$ imágenes más recientes.\n",
    "\n",
    "1. [`mjpegserver.py`](../code/mjpegserver.py): servidor de secuencias de video en formato mjpeg.\n",
    "\n",
    "1. [`histogram.py`](../code/histogram.py): histograma en vivo con opencv.\n",
    "\n",
    "1. [`histogram2.py`](../code/histogram2.py): histograma en vivo con matplotlib.\n",
    "\n",
    "1. [`surface.py`](../code/surface.py): superficie 3D de niveles de gris en vivo usando pyqtgraph.\n",
    "\n",
    "1. [`backsub.py`](../code/backsub.py): eliminación de fondo mediante MOG2.\n",
    "\n",
    "1. [`server.py`](../code/server.py): ejemplo de servidor web de imágenes capturadas con la webcam.\n",
    "\n",
    "1. [`bot`](../code/bot): bots de [Telegram](https://python-telegram-bot.org/).\n",
    "\n",
    "1. [`camshift.py`](../code/camshift.py): tracking mediante reproyección de histograma.\n",
    "\n",
    "1. [`grabcut.py`](../code/grabcut.py): segmentación de objetos interactiva mediante GrabCut.\n",
    "\n",
    "1. [`spectral.py`](../code/spectral.py): FFT en vivo.\n",
    "\n",
    "1. [`thread`](../code/thread): captura y procesamiento concurrente.\n",
    "\n",
    "1. [`testC.py`](../code/testC.py), [`inC`](../code/inC): Interfaz C-numpy.\n",
    "\n",
    "1. [`hog/pedestrian.py`](../code/hog/pedestrian.py): detector de peatones de opencv.\n",
    "\n",
    "1. [`hog/facelandmarks.py`](../code/hog/facelandmarks.py): detector de caras y landmarks de dlib.\n",
    "\n",
    "1. [`hog/hog0.py`](../code/hog/hog0.py): experimentos con hog.\n",
    "\n",
    "1. [`regressor.py`](../code/regressor.py): predictor directo de la posición de una región.\n",
    "\n",
    "1. [`sift.py`](../code/sift.py): demostración de la detección de keypoints y búsqueda de coincidencias en imágenes en vivo.\n",
    "\n",
    "1. [`lk_track.py`](../code/lk_track.py): seguimiento de puntos con el método de Lucas-Kanade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ejercicios propuestos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E1**. Modificación de los canales de color (brillo, saturación, etc.) sobre la secuencia de imágenes tomada con la webcam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E2**. Amplia `player.py` o `stream.py` para seleccionar con el ratón una región de interés (ROI) y almacenar en una lista imágenes, que pueden opcionalmente guardarse en disco. Este programa nos servirá como base para futuros ejercicios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E3**. Construye un detector de movimiento. Puedes hacer un generador que filtre la secuencia de imágenes dejando pasar solo los frames estáticos (o, si se prefiere, los que han sufrido un cambio apreciable). Puedes apoyarte en `deque.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E4**. Construye un servidor web sencillo usando [flask](http://flask.pocoo.org/) que muestre una cierta transformación, especificada en la url, de las imágenes tomadas con la cámara. Apóyate en `server.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E5**. Implementa el efecto chroma con imágenes en vivo de la webcam. Pulsando una tecla se captura el fondo y los objetos que aparezcan se superponen en otra imagen o secuencia de video. Compara el resultado con el método automático de eliminación de fondo ilustrado en `backsub.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E6**. Construye un clasificador de objetos en base a la similitud de los histogramas de color del ROI (de los 3 canales por separado). Apóyate en E2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E7**. Implementa la segmentación por color usando modelos de histograma en un programa que admite como argumento a) una carpeta con trozos de imágen que sirven como muestras de color y b) otra imagen o secuencia de video que deseamos clasificar. El resultado puede ser un conjunto de máscaras para cada clase, o una \"imagen de etiquetas\", donde diferentes colores indican cada una de las regiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E8**. Muestra el efecto de diferentes filtros sobre la imagen en vivo de la webcam. Selecciona con el teclado el filtro deseado y modifica sus posibles parámetros (p.ej. el nivel de suavizado) con las teclas de flecha. Es conveniente permitir la selección de un ROI para comparar el resultado del filtro con el resto de la imagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E9**. Escribe una aplicación de tu invención que utilice los marcadores de cara obtenidos por el *shape detector* disponible en dlib (ejemplo `facelandmarks.py`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E10**. Escribe una aplicación de reconocimiento de objetos con la webcam basada en el número de coincidencias de *keypoints*. Pulsando una tecla se pueden ir guardando modelos (p. ej. carátulas de CD, portadas de libros, cuadros de pintores, etc.). Cuando detectamos que la imagen está bastante quieta, o cuando se pulse otra tecla, calculamos los puntos de interés de la imagen actual y sus descriptores y comprobamos si hay suficientes coincidencias con los de algún modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E11** Calcula una estimación del movimiento de la cámara analizando las trayectorias obtenidas por el *tracker* de Lucas-Kanade (ejemplo `lk_track.py`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. presentación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[instalación](install.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Introducción a la asignatura\n",
    "\n",
    "- Repaso de Python, numpy y matplotib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. introducción a la imagen digital"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[gráficas](graphs.ipynb), [canales de color](color.ipynb), [indexado/stacks](stacks.ipynb), [dispositivos de captura](captura.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Imagen digital: rows, cols, depth, step. Planar or pixel order. Tipo de pixel: byte vs float\n",
    "\n",
    "- Color encoding: RGB vs YUV vs HSV\n",
    "\n",
    "- Coordendas de pixel, coordenadas normalizadas (indep de resolución), coordenadas calibradas (independiente del field of view).\n",
    "\n",
    "- Aspect ratio. Resize.\n",
    "\n",
    "- ROI, masks\n",
    "\n",
    "- Manipulación: slice regions, \"stack\" de imágenes\n",
    "\n",
    "- primitivas gráficas\n",
    "\n",
    "- captura: webcams, cameras ip, archivos de vídeo, v4l2-ctl, etc. Load / save.\n",
    "\n",
    "- entornos de conda, pyqtgraph, pycharm, spyder\n",
    "\n",
    "- Herramientas: formatos de imagen, imagemagick, gimp, mplayer/mencoder/ffmpeg, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. manipulación de imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[histograma](histogram.ipynb), [efecto chroma](chroma.ipynb), [segmentación por color](colorseg.ipynb)\n",
    "<br>\n",
    "[cuantización de color](codebook.ipynb), [transformaciones de dominio](lookup.ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Histograma, transformaciones de valor (brillo, contraste), ecualización\n",
    "\n",
    "- Transformaciones de dominio (deformaciones), lookup table.\n",
    "\n",
    "- chroma key\n",
    "\n",
    "- reproyección de histograma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. filtros digitales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[filtros de imagen](filtros.ipynb), [análisis frecuencial](fourier.ipynb), [filtrado inverso](inversefilt.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- lineal\n",
    "\n",
    "    - convolution\n",
    "    - máscaras para paso alto, bajo, etc.\n",
    "    - separabilidad\n",
    "    - integral image, box filter\n",
    "    - dominio frecuencial\n",
    "    - [inverse filtering](http://yuzhikov.com/articles/BlurredImagesRestoration1.htm), [Wiener](https://www.cis.rit.edu/class/simg782/lectures/lecture_16/lec782_05_16.pdf)\n",
    "\n",
    "\n",
    "- no lineal\n",
    "\n",
    "    - mediana\n",
    "    - min, max\n",
    "    - algoritmos generales\n",
    "\n",
    "\n",
    "- [morphological operations](http://docs.opencv.org/master/d9/d61/tutorial_py_morphological_ops.html#gsc.tab=0) (set operations)\n",
    "\n",
    "    - structuring element\n",
    "    - dilate, erode\n",
    "    - open, close\n",
    "    - gradient\n",
    "    - fill holes\n",
    "\n",
    "\n",
    "- Gaussian filter\n",
    "\n",
    "    - separabilidad\n",
    "    - cascading\n",
    "    - Fourier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4. detección de bordes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[detección de bordes](bordes.ipynb), [Canny nms en C](cannyC.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- gradiente: visualización como *vector field*\n",
    "\n",
    "- operador de Canny\n",
    "\n",
    "- transformada de Hough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. *HOG*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- HOG simple\n",
    "- pedestrians\n",
    "- face landmarks (dlib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. *keypoints*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[keypoints](keypoints.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- modelo cuadrático\n",
    "\n",
    "- blobs / saddle points (Hessian)\n",
    "\n",
    "- SIFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. optical flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[elipse de incertidumbre](covarianza.ipynb), [optical flow](harris.ipynb)\n",
    "\n",
    "- elipse de incertidumbre\n",
    "\n",
    "- cross-correlation\n",
    "\n",
    "- corners (Harris)\n",
    "\n",
    "- Lucas-Kanade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. reconocimiento de formas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[shapes](shapes.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- umbralización\n",
    "\n",
    "- manipulación de contornos\n",
    "\n",
    "- invariantes frecuenciales de forma"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
